<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
      <link rel="shortcut icon" href="../../img/favicon.ico" />
    <title>Model Based - HackaGames</title>
    <link rel="stylesheet" href="../../css/theme.css" />
    <link rel="stylesheet" href="../../css/theme_extra.css" />
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.8.0/styles/github.min.css" />
        <link href="../../style.css" rel="stylesheet" />
    
      <script>
        // Current page data
        var mkdocs_page_name = "Model Based";
        var mkdocs_page_input_path = "learning/model-based.md";
        var mkdocs_page_url = null;
      </script>
    
    <!--[if lt IE 9]>
      <script src="../../js/html5shiv.min.js"></script>
    <![endif]-->
      <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.8.0/highlight.min.js"></script>
      <script>hljs.highlightAll();</script> 
</head>

<body class="wy-body-for-nav" role="document">

  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side stickynav">
    <div class="wy-side-scroll">
      <div class="wy-side-nav-search">
          <a href="../.." class="icon icon-home"> HackaGames
        </a><div role="search">
  <form id ="rtd-search-form" class="wy-form" action="../../search.html" method="get">
      <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" title="Type search term here" />
  </form>
</div>
      </div>

      <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <ul>
                <li class="toctree-l1"><a class="" href="../../..">ktorz <</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../..">Home</a>
                </li>
              </ul>
              <p class="caption"><span class="caption-text">First-Steps</span></p>
              <ul>
                  <li class="toctree-l1"><a class="reference internal" href="../../hello/install/">Install</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../hello/first-bot/">First Bot</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../hello/multi-player/">Multiplayer</a>
                  </li>
              </ul>
              <p class="caption"><span class="caption-text">Games</span></p>
              <ul>
                  <li class="toctree-l1"><a class="reference internal" href="../../games/py421/">Py4.2.1</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../games/connect4/">Connect4</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../games/tictactoe/">TicTacToe</a>
                  </li>
              </ul>
              <p class="caption"><span class="caption-text">Tuto: Learning</span></p>
              <ul class="current">
                  <li class="toctree-l1"><a class="reference internal" href="../policy/">Policy</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../qlearning/">Q-Learning</a>
                  </li>
                  <li class="toctree-l1 current"><a class="reference internal current" href="./">Model Based</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../speed-up/">Speed-up</a>
                  </li>
              </ul>
              <p class="caption"><span class="caption-text">Under the hood</span></p>
              <ul>
                  <li class="toctree-l1"><a class="reference internal" href="../../hood/api/">Protocol API</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../hood/pod/">Pod Class</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../hood/newgame/">New Game</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../hood/testdriven/">Test-Driven</a>
                  </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../../resources/policy.zip"></a>
                </li>
              </ul>
      </div>
    </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">
      <nav class="wy-nav-top" role="navigation" aria-label="Mobile navigation menu">
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../..">HackaGames</a>
        
      </nav>
      <div class="wy-nav-content">
        <div class="rst-content"><div role="navigation" aria-label="breadcrumbs navigation">
  <ul class="wy-breadcrumbs">
    <li><a href="../.." class="icon icon-home" aria-label="Docs"></a></li>
          <li class="breadcrumb-item">Tuto: Learning</li>
      <li class="breadcrumb-item active">Model Based</li>
    <li class="wy-breadcrumbs-aside">
    </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
            <div class="section" itemprop="articleBody">
              
                <h1 id="model-based-learning-markov-decision-process">Model Based Learning: Markov-Decision-Process</h1>
<p>This tutorial aims to compute a policy from learned transitions and rewards on <em>py421</em> game.</p>
<p>To do that we need to record a transition function and a average reward function.</p>
<p>With dictionary, the transition function would be a dictionary over states returning dictionaries over actions returning dictionaries over reached states' returning the number of times the transition is experienced.</p>
<p>In case of <em>Py421</em>, an object about <span class="arithmatex">\(128 \times 8 \times 128\)</span> counters, but the reward function would be simplest.</p>
<p>The model is based on Markov Decision Process (MDP) framework:</p>
<ul>
<li><a href="https://en.wikipedia.org/wiki/Markov_decision_process">On Wikipedia</a></li>
</ul>
<p>After enough experiments, it would be possible to process this MDP model function to compute a policy.</p>
<h3 id="initialize-your-mdp-bot">Initialize your MDP Bot:</h3>
<p>First we require specific model methods:  <code>state()</code> to transform game variable affectations into a dictionary entry, <code>updateModel(state_past, action, state_present, reward)</code> to use to increase knowledge about transition and reward.</p>
<pre><code class="language-python">    # Model:
    def state(self) :
        return f&quot;{self._horizon}-{self._dices[0]}-{self._dices[1]}-{self._dices[2]}&quot;

    def updateModel( self, past_state, action, present_state, reward ):
        print( f&quot;transition: {past_state}, {action}, {present_state}&quot;)
        print( f&quot;reward: {reward}\n&quot;)
</code></pre>
<p>Then it is possible to prepare <code>perception</code>s method with model update:</p>
<pre><code class="language-python">    # Player interface :
    def wakeUp(self, playerId, numberOfPlayers, gameConf):
        self._state= &quot;3-4-2-1&quot;
        self._action= &quot;r-r-r&quot;
        self._score= 0

    def perceive(self, gameState):
        self._horizon= gameState.child(1).integer(1)
        self._dices= gameState.child(2).integers()
        newScore= gameState.child(2).value(1)
        # Learn:
        newState= self.state()
        self.updateModel(
            self._state, self._action,
            newState, newScore-self._score
        )
        # Switch:
        self._state= newState
        self._score= newScore
</code></pre>
<h3 id="record-transitions-and-reward">Record transitions and reward:</h3>
<p>The <code>updateModel</code> method updates counters and average rewards. 
My advice is to keep also a counter <code>experiments</code> over the amount of time the <em>Bot</em> tests the same action into the same state.
At some point, the <code>updateModel</code> method, the update should be something like:</p>
<pre><code class="language-python">        # Roling reward average :
        total= self._counterActions[past_state][action]
        oldReward= self._rewards[past_state][action]
        self._rewards[past_state][action]= (oldReward * total + reward) / (total+1)
        # Update counters
        self._counterExperiences[past_state][action]+= 1
        self._counterTransitions[past_state][action][present_state]+= 1
</code></pre>
<p>Naturally, it supposes that you already create the dictionaries and the entrances...
Use json package to save your model (sometimes) into your <code>sleep</code> method.</p>
<h2 id="process-model">Process model.</h2>
<p>This is the interesting part of the exercice.
From the transitions and rewards we want to compute the optimal policy <span class="arithmatex">\(\pi^*\)</span>
For that purpose, we recommand to apply Value Iteration (cf. <a href="https://en.wikipedia.org/wiki/Markov_decision_process">On Wikipedia</a>)</p>
<blockquote>
<p><strong>valueIteration:</strong>
<em>Input:</em> an <strong>MDP:</strong> <span class="arithmatex">\(\langle S, A, T, R \rangle\)</span> ; precision error: <em><span class="arithmatex">\(\epsilon\)</span></em> ; discount factor: <em><span class="arithmatex">\(\gamma\)</span></em> ; initial <strong>values(s)</strong></p>
<ol>
<li>Repeat until: <strong>maximal delta &lt; <span class="arithmatex">\(\epsilon\)</span></strong> <br /> For each state <strong><span class="arithmatex">\(s \in S\)</span></strong></li>
</ol>
<p><span class="arithmatex">\(\qquad \qquad -\)</span> Search the action <strong><span class="arithmatex">\(a^*\)</span></strong> maximizing the Bellman Equation on <strong><span class="arithmatex">\(s\)</span></strong></p>
<div class="arithmatex">\[a^*= \arg\max_{a \in A}\left( \mathit{value}(s, a) \right)\]</div>
<div class="arithmatex">\[\mathit{value}(s, a)= R(s, a) + \gamma \sum_{s'\in S} T(s,a,s') \times \mathit{values}(s')\]</div>
<p><span class="arithmatex">\(\qquad \qquad -\)</span> Set <em><span class="arithmatex">\(\pi(s)= a^*\)</span></em> and _<span class="arithmatex">\(\mathit{values}(s)= \mathit{computeValue}(s,  a^*)\)</span></p>
<p><span class="arithmatex">\(\qquad \qquad -\)</span> Compute the delta value between the previous and the new <em><span class="arithmatex">\(\mathit{values}(s)\)</span></em></p>
<p><em>Output:</em> an optimal <span class="arithmatex">\(\pi^*\)</span> and the associated V-values</p>
</blockquote>
<p>The policy can be updated every <span class="arithmatex">\(500\)</span> <code>sleep</code> with a call to your new <code>valueIteration</code>.
To notice that <code>self._transition</code> is not directly usable. Values need to be transformed to probabilities (<code>self._transition[s][a][s'] / self._experiements[s][a]</code>).</p>
<p>Furthermore, any state not defined into <code>self._transition</code> can be considered as a terminal state (<code>len(V) &gt;= len(self._transition)</code>).
If necessary, terminal state has only the <code>keep-keep-keep</code> action and the transition falls into the same state (itself) with probability of <span class="arithmatex">\(1\)</span> and a reward of <span class="arithmatex">\(0\)</span>.</p>
<h2 id="exploit">Exploit.</h2>
<p>Use the policy at decision step. 
However, until a sufisant number of experiments are performed, the model and so the policy cannot be completelly trusted.
A random exporation ratio need to be design as for <em>Q-Learning</em>.</p>
              
            </div>
          </div><footer>
    <div class="rst-footer-buttons" role="navigation" aria-label="Footer Navigation">
        <a href="../qlearning/" class="btn btn-neutral float-left" title="Q-Learning"><span class="icon icon-circle-arrow-left"></span> Previous</a>
        <a href="../speed-up/" class="btn btn-neutral float-right" title="Speed-up">Next <span class="icon icon-circle-arrow-right"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <!-- Copyright etc -->
  </div>

  Built with <a href="https://www.mkdocs.org/">MkDocs</a> using a <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>.
</footer>
          
        </div>
      </div>

    </section>

  </div>

  <div class="rst-versions" role="note" aria-label="Versions">
  <span class="rst-current-version" data-toggle="rst-current-version">
    
    
      <span><a href="../qlearning/" style="color: #fcfcfc">&laquo; Previous</a></span>
    
    
      <span><a href="../speed-up/" style="color: #fcfcfc">Next &raquo;</a></span>
    
  </span>
</div>
    <script src="../../js/jquery-3.6.0.min.js"></script>
    <script>var base_url = "../..";</script>
    <script src="../../js/theme_extra.js"></script>
    <script src="../../js/theme.js"></script>
      <script src="../../javascripts/mathjax.js"></script>
      <script src="https://unpkg.com/mathjax@3/es5/tex-mml-chtml.js"></script>
      <script src="../../search/main.js"></script>
    <script>
        jQuery(function () {
            SphinxRtdTheme.Navigation.enable(true);
        });
    </script>

</body>
</html>
