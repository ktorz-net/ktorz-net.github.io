<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
      <link rel="shortcut icon" href="../../img/favicon.ico" />
    <title>Speed-up - HackaGames</title>
    <link rel="stylesheet" href="../../css/theme.css" />
    <link rel="stylesheet" href="../../css/theme_extra.css" />
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.8.0/styles/github.min.css" />
        <link href="../../style.css" rel="stylesheet" />
    
      <script>
        // Current page data
        var mkdocs_page_name = "Speed-up";
        var mkdocs_page_input_path = "learning/speed-up.md";
        var mkdocs_page_url = null;
      </script>
    
    <!--[if lt IE 9]>
      <script src="../../js/html5shiv.min.js"></script>
    <![endif]-->
      <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.8.0/highlight.min.js"></script>
      <script>hljs.highlightAll();</script> 
</head>

<body class="wy-body-for-nav" role="document">

  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side stickynav">
    <div class="wy-side-scroll">
      <div class="wy-side-nav-search">
          <a href="../.." class="icon icon-home"> HackaGames
        </a><div role="search">
  <form id ="rtd-search-form" class="wy-form" action="../../search.html" method="get">
      <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" title="Type search term here" />
  </form>
</div>
      </div>

      <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <ul>
                <li class="toctree-l1"><a class="" href="../../..">ktorz <</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../..">Home</a>
                </li>
              </ul>
              <p class="caption"><span class="caption-text">First-Steps</span></p>
              <ul>
                  <li class="toctree-l1"><a class="reference internal" href="../../hello/install/">Install</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../hello/first-bot/">First Bot</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../hello/multi-player/">Multiplayer</a>
                  </li>
              </ul>
              <p class="caption"><span class="caption-text">Games</span></p>
              <ul>
                  <li class="toctree-l1"><a class="reference internal" href="../../games/py421/">Py4.2.1</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../games/connect4/">Connect4</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../games/tictactoe/">TicTacToe</a>
                  </li>
              </ul>
              <p class="caption"><span class="caption-text">Tuto: Learning</span></p>
              <ul class="current">
                  <li class="toctree-l1"><a class="reference internal" href="../policy/">Policy</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../qlearning/">Q-Learning</a>
                  </li>
                  <li class="toctree-l1 current"><a class="reference internal current" href="./">Speed-up</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../model-based/">Model Based</a>
                  </li>
              </ul>
              <p class="caption"><span class="caption-text">Under the hood</span></p>
              <ul>
                  <li class="toctree-l1"><a class="reference internal" href="../../hood/api/">Protocol API</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../hood/pod/">Pod Class</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../hood/newgame/">New Game</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../hood/testdriven/">Test-Driven</a>
                  </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../../resources/policy.zip"></a>
                </li>
              </ul>
      </div>
    </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">
      <nav class="wy-nav-top" role="navigation" aria-label="Mobile navigation menu">
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../..">HackaGames</a>
        
      </nav>
      <div class="wy-nav-content">
        <div class="rst-content"><div role="navigation" aria-label="breadcrumbs navigation">
  <ul class="wy-breadcrumbs">
    <li><a href="../.." class="icon icon-home" aria-label="Docs"></a></li>
          <li class="breadcrumb-item">Tuto: Learning</li>
      <li class="breadcrumb-item active">Speed-up</li>
    <li class="wy-breadcrumbs-aside">
    </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
            <div class="section" itemprop="articleBody">
              
                <h1 id="speed-up">Speed-Up</h1>
<p>The advantage of <em>Model-Based</em> learning compared to solutions like <em>Q-Learning</em> is to provide some guarantees on the computed policy.
However, the main goal in machine learning is to build coherent policies as fast as possible (and by doing so, to be capable of scaling up).</p>
<p>That for, learning directly the policy is generally preferred in Reinforcement Learning.
However, solutions like <em>Q-Learning</em> remains inapplicable in real-life problems, and solutions need to be set up to bypass combinatorial explosions.</p>
<h2 id="experiments">Experiments</h2>
<p>First we need to set up an environment to save and monitor our progress in learning policies (or models).</p>
<p>One way to do that is to plot the evolution of the strategy during the learning.
For instance, the package <a href="https://matplotlib.org/stable/tutorials/introductory/pyplot.html">pyplot</a> provides simple tools in this way.</p>
<p>Let generate a plot with one points every <span class="arithmatex">\(500\)</span> games for instance at sleep time.</p>
<pre><code class="language-python">import matplotlib.pyplot as plt

Class Bot:
    def __init__(self):
        # Progress
        self._results= []
        self._evals= []
        # Q-Learning attributes

...
    def sleep(self, result):
        self._results.append(result)
        if len(self._results) == 500 :
            self._evals.append( sum(self._results)/500.0 )
            self._results= []
            self.drawEvaluations()

    def drawEvaluations(self) :
        plt.plot( 
            [ i*500 for i in range(len(self._evals)) ],
            self._evals )
        plt.savefig( &quot;output.png&quot; )
        plt.clf()
</code></pre>
<p>Itâ€™s also possible to save the <em>QValues</em> dictionary and the average score in a file for later use, for instance with <code>json</code> package.</p>
<pre><code class="language-python">fileContent= open(&quot;my-file.json&quot;, &quot;w&quot;)
json.dump( aDictionary, fileContent, sort_keys=True, indent=2 )
fileContent.close()
</code></pre>
<p>Then the load function can rebuild a <code>.json</code> dictionary.</p>
<pre><code class="language-python">if os.path.isfile( &quot;my-file.json&quot; ) :
    fileContent= open(&quot;my-file.json&quot;)
    aDictionary = json.load(fileContent)
    fileContent.close()
</code></pre>
<h2 id="dynamic-learning-parameters">Dynamic Learning Parameters</h2>
<p>Greedy exploit/Explore ratio is limited, notably when the Q-values become stables.
A first solution is to change the ratio dynamically while the systems record experiments.</p>
<p>Typically, QLearning can be configured with a high exploration probability during the first benches of games, and decrease this probability with experience (i.e. each time the <em>bot</em> is wape-up again).
A similar mechanism can be applied to the learning rate.</p>
<p>The parameter of the Qlearning is not directly the Exploration/Explotation ratio and the learning rate,
but the initial and final values, and it decreases speed.</p>
<!-- ## Probabilistic Policy

Greedy exploit/Explore ratio is limited, notably when the Q-values become stables.
A first solution is to change the ratio dynamically while the systems record experiments.
Another solution consists of implementing [probabilistic policies](https://en.wikipedia.org/wiki/Reinforcement_learning#policy).

Using probabilistic policies in _Q-Learning_ the probability to take an action rather than another increase with the differences in _Q-Values_.
-->

<h2 id="factorized-policy">Factorized Policy</h2>
<p>The main idea is that a same action could be defined for several 'similar' states.
So is it possible to group 'similar' states together, to learn faster.</p>
<p><em>Py421</em> advantages the combinations <em>4-2-1</em>, <em>1-1-1</em> or <em>X-1-1</em>. 
A first idea could be to focus state definition to target those combinations.</p>
<p>This idea modeled as a tree will lookalike: <br />
<img alt="DT for 421" src="../dt-421.svg" /></p>
<p>This tree can be implemented with a <em>"if-then-else"</em> procedure into a QLearner Bot, to learn a good behavior on Py421 game only over 7 states.
As a result, learning should be very fast but with a final behavior less performant than learning applied over all the <em>168</em> game states.</p>
<p>In fact, such a solution is close to <em>Decision Tree</em> approaches, a decision support based on a recursive partitioning structure <a href="https://en.wikipedia.org/wiki/Decision_tree">Wikipedia</a>.</p>
              
            </div>
          </div><footer>
    <div class="rst-footer-buttons" role="navigation" aria-label="Footer Navigation">
        <a href="../qlearning/" class="btn btn-neutral float-left" title="Q-Learning"><span class="icon icon-circle-arrow-left"></span> Previous</a>
        <a href="../model-based/" class="btn btn-neutral float-right" title="Model Based">Next <span class="icon icon-circle-arrow-right"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <!-- Copyright etc -->
  </div>

  Built with <a href="https://www.mkdocs.org/">MkDocs</a> using a <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>.
</footer>
          
        </div>
      </div>

    </section>

  </div>

  <div class="rst-versions" role="note" aria-label="Versions">
  <span class="rst-current-version" data-toggle="rst-current-version">
    
    
      <span><a href="../qlearning/" style="color: #fcfcfc">&laquo; Previous</a></span>
    
    
      <span><a href="../model-based/" style="color: #fcfcfc">Next &raquo;</a></span>
    
  </span>
</div>
    <script src="../../js/jquery-3.6.0.min.js"></script>
    <script>var base_url = "../..";</script>
    <script src="../../js/theme_extra.js"></script>
    <script src="../../js/theme.js"></script>
      <script src="../../javascripts/mathjax.js"></script>
      <script src="https://unpkg.com/mathjax@3/es5/tex-mml-chtml.js"></script>
      <script src="../../search/main.js"></script>
    <script>
        jQuery(function () {
            SphinxRtdTheme.Navigation.enable(true);
        });
    </script>

</body>
</html>
